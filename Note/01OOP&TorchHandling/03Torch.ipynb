{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Torch\n",
    "\n"
   ],
   "id": "bd787db6cd7e166b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Torch Basic\n",
    "\n",
    "- `torch.Tensor`는 다차원 배열을 처리하는 PyTorch의 기본 데이터 구조로, Numpy 배열과 유사하지만 GPU 가속 및 자동 미분 기능을 제공한다.\n",
    "- Tensor는 다차원 행렬을 의미하는 것으로, 이름부터 고차원의 행렬을 연산하기 위해 탄생하였다고 봐도 무방하다."
   ],
   "id": "e964baee8f6e5cb6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np_array = np.array([[1, 2], [3, 4]])\n",
    "print(\"Numpy Array:\\n\", np_array)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`numpy` 형태의 데이터는 다음과 같이 `type()`로 확인하면 `np.ndarray`가 나온다.",
   "id": "75757aa70ae7f85f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(np_array)",
   "id": "8ccb9868f8223f61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "마찬가지로, Torch는 torch.Tensor형태의 타입이 나온다.",
   "id": "cead1bc552ec0732"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch_tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"Torch Tensor:\\n\", torch_tensor)"
   ],
   "id": "98ea8294727e63ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(torch_tensor)",
   "id": "fb2b3130d612aef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "shapes는 numpy와 사용이 굉장히 유사하다. 출력 형태는 `torch.Size()`로 나온다.",
   "id": "e2a1dffd0934707d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np_array.shape # shapes",
   "id": "f38122dad8315805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch_tensor.shape",
   "id": "157fd09913aae67b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "일반적으로 행렬은 다음과 같이 생성한다. numpy의 기능과 굉장히 유사함으로 사용에 큰 지장은 없다. 기본 데이터 타입은 `float64`로 출력된다.",
   "id": "96bffb8166576b46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 0행렬의 경우\n",
    "zeros_tensor = torch.zeros(3, 3)\n",
    "print(\"Zeros Tensor:\\n\", zeros_tensor)"
   ],
   "id": "36a6aba9d099ea54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2 * 2 형태의 1로 이뤄진 행렬\n",
    "ones_tensor = torch.ones(2, 2)\n",
    "print(\"Ones Tensor:\\n\", ones_tensor)"
   ],
   "id": "81989603c0103b79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4x4 크기의 랜덤한 값을 가진 텐서, 랜덤변수는 정규분포에서 출력되었다고 가정한다.\n",
    "random_tensor = torch.randn(4, 4)\n",
    "print(\"Random Tensor:\\n\", random_tensor)"
   ],
   "id": "92ef65621fc17604",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "연산 결과는 `.numpy()` method를 통해 numpy형태로 변환 가능하다.",
   "id": "e99b0e76119b5569"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "random_tensor_numpy = random_tensor.numpy()",
   "id": "decd1e94cf18d950",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "random_tensor_numpy",
   "id": "e7a182db7f03c8ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(type(random_tensor_numpy)) # numpy.ndarray",
   "id": "eacd07921309c52a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3차원 이상의 경우 tensor는 다음과 같이 표현된다. numpy와 마찬가치로 2차원 행렬이 줄바꿈을 기준으로 표현되는 형식이다.",
   "id": "b8b55d462374c887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_tensor_3d = torch.randn(4, 4, 4)\n",
    "print('Random Tensor 3D:\\n', random_tensor_3d)"
   ],
   "id": "d6ed77d4070e43da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.1 기본 텐서 연산\n",
    "\n",
    "- `numpy`와 마찬가지로 다차원 행렬의 연산을 수행할 수 있다."
   ],
   "id": "7b12486d2d4fd2bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])"
   ],
   "id": "ee54cbfeb1d822cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a",
   "id": "6b46745db8e88679",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "b",
   "id": "9c9e71061618e9a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 덧셈 (add)\n",
    "print(\"Addition:\\n\", torch.add(a, b))"
   ],
   "id": "7e505a96f69c402f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "element별로 곱셈을 수행하기 위해서는 `mul()`함수를 사용한다.",
   "id": "cd004fee8d777ce1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 곱셈 (요소별, mul)\n",
    "print(\"Element-wise Multiplication:\\n\", torch.mul(a, b))"
   ],
   "id": "86137b554288860",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "행렬곱 연산 수행을 위해서는 `matmul()` 함수를 사용한다.",
   "id": "919d27174f28aa63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 행렬 곱 (matmul)\n",
    "print(\"Matrix Multiplication:\\n\", torch.matmul(a, b))"
   ],
   "id": "6537a40484e3d4af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "요소의 개수와 행렬 전체의 크기만 맞춘다면, numpy와 마찬가지로 shape를 변경할 수 있다 (reshape)",
   "id": "7b761bd2b994a134"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 텐서의 크기 변경 (reshape)\n",
    "reshaped_tensor = a.reshape(4, 1)\n",
    "print(\"Reshaped Tensor:\\n\", reshaped_tensor)"
   ],
   "id": "c03ed6ef3efdae6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`view()` method를 사용하면 메모리의 추가적인 할당 없이, 기존 데이터를 공유하여 reshape을 한다. 메모리를 절약할 수 있다는 점에서 장점이 있지만, 동시에 데이터가 공유되기 때문에 인스턴스화된 하나의 변수에서 값을 변경할 경우 나머지 하나에도 동일하게 값이 변경되므로 주의해야 한다.",
   "id": "265a8d3b44a3931c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# view를 통한 형태 변경 (기존 데이터 공유)\n",
    "viewed_tensor = a.view(1, 4)\n",
    "print(\"Viewed Tensor:\\n\", viewed_tensor)"
   ],
   "id": "28715adfa611b1cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a",
   "id": "42e92f532f754737",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "viewed_tensor[0][0] = 10 # 새롭게 인스턴스와된 변수의 값을 변경",
   "id": "2ac8bc16094880d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "viewed_tensor",
   "id": "b79234e799b230a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a",
   "id": "d9302c186a4f583a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`squeeze()` method를 사용해 차원을 축소할 수 있다. 차원이 1인 축(axes)을 제거하여 텐서의 차원을 축소하는 기능을 수행한다.",
   "id": "de17e8e23ea58e2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "expanded_tensor = torch.tensor([[[1, 2, 3]]])  # (1, 1, 3) -> (3, )\n",
    "squeezed_tensor = expanded_tensor.squeeze()"
   ],
   "id": "a5a05c6f244dc4d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "expanded_tensor # (1, 1, 3)",
   "id": "c7d2f8e01fe51ab7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "squeezed_tensor # (3, )",
   "id": "3433535b1b021c29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "squeeze는 데이터 복사가 없으며, 원본 텐서의 메모리를 공유기 때문에 `view()`와 마찬가지로 인스턴스화된 어느 한 변수에서 값을 변경할 경우, 다른 변수들 또한 동일하게 값이 변하므로 유의해야 한다.",
   "id": "b7ce169a35360093"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "squeezed_tensor[0] = 10 # 새로운 값 변경",
   "id": "5f2c67cc517beda2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "squeezed_tensor",
   "id": "75b2e7606ee79c9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "expanded_tensor",
   "id": "900e91c166d20ff8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.2 GPU 연산 사용\n",
    "\n",
    "- Torch는 GPU를 활용해 연산을 가속할 수 있다. Nvidia 계열 GPU를 사용하는 경우 `.cuda()` 또는 `.to(device)`를 사용한다. \n",
    "- Silicon Mac을 사용하는 경우 gpu를 `mps:0`로 설정하면 GPU 가속을 사용할 수 있다.\n",
    "- Nvidia GPU혹은 Apple M 시리즈를 사용하지 않는다면 cpu로 연산을 진행해도 된다. 다만, 학습 속도는 굉장히 느려진다."
   ],
   "id": "6bb72a5fec9e8064"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # cuda 사용자인 경우 사용.\n",
    "device = torch.device(\"mps:0\")\n",
    "print(\"Using device:\", device)"
   ],
   "id": "bb13da9923ac16e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cpu_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "gpu_tensor = cpu_tensor.to(device) # 메모리 영역이 다르기 때문에 device를 전달해 주어야 함\n",
    "\n",
    "print(\"Tensor on device:\", gpu_tensor)"
   ],
   "id": "bd9ce9bd88fbf93e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Gradient\n",
    "\n",
    "- Torch의 `Autograd` 기능은 신경망 학습 과정에서 역전파(Backpropagation)를 수행하기 위해 Gradient를 자동으로 계산한다.\n",
    "- 이를 위해 `requires_grad` 속성과 `backward()` method를 사용한다."
   ],
   "id": "7e138a6181f42c84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.1 자동 미분\n",
    "\n",
    "- `torch.autograd`는 텐서의 연산 기록을 추적하여 자동으로 **미분(gradient)**을 계산한다.\n",
    "- 텐서에 `requires_grad=True`를 설정하면 연산 그래프가 기록되며, backward() 호출 시 그래디언트가 계산된다."
   ],
   "id": "dd70c329546ec244"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x = torch.tensor(2.0, requires_grad = True) # 자동으로 연산을 추적",
   "id": "e813f3f9b921c9f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "아래와 같은 식을 생각해 보자\n",
    "\n",
    "$$y = x^2 + 3x + 5$$\n",
    "\n",
    "이 식을 미분하면 다음과 같이 된다\n",
    "\n",
    "$$y^\\prime = 2x + 3$$\n",
    "\n",
    "위 식을 torch를 이용해 미분해 보자"
   ],
   "id": "911643fc9b598585"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y = x**2 + 3*x + 5\n",
    "\n",
    "y.backward() # backward() 호출하여 y를 x에 대해 미분"
   ],
   "id": "2064901e32016e1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "결과를 확인하면, 미분이 잘 된 것을 알 수 있다.",
   "id": "ebd9584d77803178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.grad # x = 2일때, 일계도함수의 값",
   "id": "dde36309ac43ab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "변수가 여러개일 때에도 미분이 가능하다.",
   "id": "25c6e4a7923908ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)",
   "id": "95d60ff0085b578a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y = 2 * x**2 + 3 * x\n",
    "y.sum().backward() # 스칼라 값을 만들기 위해 합을 구한 후 backward() 호출"
   ],
   "id": "cf1fe6b36702a2d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.grad # 각 x값에 대해서 미분값을 출력",
   "id": "a870ec6fe20cf7ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2 자동 미분 추적 금지\n",
    "\n",
    "학습이 시작된 이후에는 추적이 필요하지만, 학습이 완료되고 테스트를 할 때에는 gradient 값을 업데이트 할 필요가 없다. 이럴 때에는 `torch.no_grad`를 사용한다."
   ],
   "id": "526b8b8a8cdfebd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "\n",
    "with torch.no_grad(): # 실제로는 테스트 데이터에 대해서 no_grad()를 사용한다.\n",
    "    y = x ** 2 + 3 * x\n",
    "    print(\"Value of y (no_grad):\", y)"
   ],
   "id": "cc8f50bb11740bde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.grad # None",
   "id": "43e89f4fafe2474d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "또는 `detach()`를 사용하여 그래디언트 추적 방지를 할 수도 있다. 이를 이용하면 특정 텐서에서만 그래디언트 계산에서 제외할 수 있다. `detach()`는 그래디언트 추적을 비활성화하여, 동일한 데이터를 새로운 텐서로 반환한다.",
   "id": "6774cd63de9bd052"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "y = x ** 2"
   ],
   "id": "519a14c250402ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "z = y.detach() # x와 연결이 끊어짐",
   "id": "c429f87835011aca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "z.requires_grad",
   "id": "61c4a7a3ceb39b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Gradient 초기화\n",
    "\n",
    "torch는 gradient를 누적 방식으로 계산하므로, 반복 학습 시마다 그래디언트를 초기화해야 한다. 이를 수행하지 않으면 값이 누적되어 학습 결과가 중복될 수 있다."
   ],
   "id": "4524b051b571cfdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x = torch.tensor(2.0, requires_grad=True)",
   "id": "cf440cbadfcbf990",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y1 = x ** 2\n",
    "y1.backward()\n",
    "print(\"First Gradient:\", x.grad)  # dy/dx = 2x = 4"
   ],
   "id": "ab66932a49e14557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y1 = x ** 2\n",
    "y1.backward()\n",
    "print(\"Second Gradient:\", x.grad) # 여러 번 backward() 호출 시 그래디언트가 누적됨"
   ],
   "id": "28b5ef551c5f3b8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x.grad.zero_() # zero_ 수행 후 새로운 연산 실행\n",
    "y2 = x ** 2\n",
    "y2.backward()\n",
    "print(\"Second Gradient:\", x.grad)  # dy/dx = 3x^2 = 12"
   ],
   "id": "ff882a26bfb3deb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Chain Rules\n",
    "\n",
    "- Chain Rule은 일종의 합성함수 연산이라고 볼 수 있다.\n",
    "- torch에서는 자동으로 Chain Rule을 적용하여 다단계 연산의 그래디언트를 계산할 수 있다."
   ],
   "id": "7bd8278aac08c81a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "z = 3 * y + 2\n",
    "\n",
    "z.backward()  # dz/dx = 3 * dy/dx = 3 * 2x = 6"
   ],
   "id": "9d4560373a07c2b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.grad",
   "id": "1bdc2b1588e676e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.5 Jacobian Matrix\n",
    "\n",
    "- `torch.autograd.grad()`를 이용해 복수의 입력과 출력에 대한 미분(자코비안 행렬)을 계산할 수 있다."
   ],
   "id": "7d907cc6e6cad17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = x * x  # [x^2, y^2]"
   ],
   "id": "9153968a3b1ff3a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gradients = torch.autograd.grad(outputs=y, inputs=x, grad_outputs=torch.tensor([1.0, 1.0]))",
   "id": "5c0b68f667db5170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "출력은 tuple 형태이므로 값을 사용하기 위해서는 첫 번째 값(0번째 인덱스)을 사용해야 한다.",
   "id": "34b9eae7d38aaa6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gradients",
   "id": "42ead340493b9e49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Optimization & Loss",
   "id": "d74a2c4e9b2c7344"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y_true = torch.tensor([2.0, 4.0, 6.0]) \n",
    "w = torch.tensor(1.0, requires_grad=True) # weight initialization"
   ],
   "id": "cee471d8dc2c5135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def loss_fn(y_pred, y_true):\n",
    "    return ((y_pred - y_true) ** 2).mean()\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred = w * x\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "\n",
    "    loss.backward()  # 그래디언트 계산\n",
    "    with torch.no_grad():\n",
    "        w -= 0.01 * w.grad  # 가중치 업데이트\n",
    "        w.grad.zero_()  # 그래디언트 초기화"
   ],
   "id": "19c07ff64b6fd2b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:47:00.038070Z",
     "start_time": "2025-01-25T10:47:00.028646Z"
    }
   },
   "cell_type": "code",
   "source": "w.item() # optimized weight",
   "id": "eacd37194eb45a5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9999443292617798"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Example. Portfolio Optimization",
   "id": "58835800820d2e33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:50:52.838911Z",
     "start_time": "2025-01-25T10:50:47.573165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "\n",
    "data = yf.download(\n",
    "    ['AAPL','XOM','WMT'],\n",
    "    start = '2020-01-01',\n",
    "    progress = False\n",
    ")['Close']"
   ],
   "id": "c94d4ebb7f890571",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:51:18.010797Z",
     "start_time": "2025-01-25T10:51:18.005461Z"
    }
   },
   "cell_type": "code",
   "source": "ret = data.pct_change()",
   "id": "55cc253b41afc954",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:20.300411Z",
     "start_time": "2025-01-25T10:57:20.289616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "expected_returns = torch.tensor(\n",
    "    ret.mean().values * 252,\n",
    "    dtype = torch.float32\n",
    ")"
   ],
   "id": "a633f7d5a0b8e15",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:20.594435Z",
     "start_time": "2025-01-25T10:57:20.591786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cov_matrix = torch.tensor(\n",
    "    ret.cov().values * 252,\n",
    "    dtype = torch.float32\n",
    ")"
   ],
   "id": "9f3c570198c4af8a",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:20.945791Z",
     "start_time": "2025-01-25T10:57:20.941986Z"
    }
   },
   "cell_type": "code",
   "source": "expected_returns",
   "id": "1ee2ed2c24f14b76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2655, 0.1980, 0.1436])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:21.314083Z",
     "start_time": "2025-01-25T10:57:21.311194Z"
    }
   },
   "cell_type": "code",
   "source": "cov_matrix",
   "id": "2062dc7bc7b0450c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1002, 0.0256, 0.0304],\n",
       "        [0.0256, 0.0507, 0.0134],\n",
       "        [0.0304, 0.0134, 0.1180]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:21.952430Z",
     "start_time": "2025-01-25T10:57:21.950261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "weights = torch.tensor([0.33, 0.33, 0.34], requires_grad=True)"
   ],
   "id": "a5d6e1c93b3284f6",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:22.597307Z",
     "start_time": "2025-01-25T10:57:22.594949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def portfolio_risk(weights, cov_matrix):\n",
    "    weights_2d = weights.unsqueeze(0)  # (n,) -> (1, n)\n",
    "    risk = torch.matmul(weights_2d, torch.matmul(cov_matrix, weights.unsqueeze(1)))  # (1, n) * (n, n) * (n, 1)\n",
    "    return risk.squeeze()  # 스칼라 값 반환\n",
    "\n",
    "def portfolio_return(weights, expected_returns):\n",
    "    return torch.dot(weights, expected_returns)"
   ],
   "id": "427345c6d31f2990",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:23.026348Z",
     "start_time": "2025-01-25T10:57:22.976826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.SGD([weights], lr=0.01) # optimization target : 분산 최소화\n",
    "\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()  # 그래디언트 초기화. 이전에 학습한 정보를 지움으로써 학습 데이터가 겹치는 것을 방지.\n",
    "    loss = portfolio_risk(weights, cov_matrix)  # 손실 함수 (리스크 최소화), 오차 최소화를 목표로 함\n",
    "    loss.backward()  # 그래디언트 계산\n",
    "    optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "    # 제약 조건 적용 (가중치 합 1, 음수 불가)\n",
    "    with torch.no_grad():\n",
    "        weights[:] = torch.clamp(weights, min=0)  # 음수를 방지하기 위함\n",
    "        weights /= weights.sum()  # 합이 1이 되도록 조정\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Risk: {loss.item()}, Weights: {weights.tolist()}\")"
   ],
   "id": "e3aa6ecfd5842ff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Risk: 0.04548601806163788, Weights: [0.3298613131046295, 0.33030465245246887, 0.33983397483825684]\n",
      "Epoch 50, Risk: 0.04475940018892288, Weights: [0.3225419819355011, 0.34618452191352844, 0.33127352595329285]\n",
      "Epoch 100, Risk: 0.04402049630880356, Weights: [0.314426451921463, 0.36337941884994507, 0.3221941292285919]\n",
      "Epoch 150, Risk: 0.04327748343348503, Weights: [0.3054577112197876, 0.3819565773010254, 0.3125856816768646]\n",
      "Epoch 200, Risk: 0.04254036396741867, Weights: [0.29557958245277405, 0.4019787311553955, 0.30244165658950806]\n",
      "Epoch 250, Risk: 0.04182100668549538, Weights: [0.28473812341690063, 0.423501193523407, 0.29176074266433716]\n",
      "Epoch 300, Risk: 0.04113326221704483, Weights: [0.27288269996643066, 0.44657066464424133, 0.280546635389328]\n",
      "Epoch 350, Risk: 0.040492936968803406, Weights: [0.2599673867225647, 0.47122326493263245, 0.26880934834480286]\n",
      "Epoch 400, Risk: 0.039917752146720886, Weights: [0.24595271050930023, 0.4974818229675293, 0.25656551122665405]\n",
      "Epoch 450, Risk: 0.039427176117897034, Weights: [0.23080717027187347, 0.5253533720970154, 0.24383944272994995]\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:34.342108Z",
     "start_time": "2025-01-25T10:57:34.339314Z"
    }
   },
   "cell_type": "code",
   "source": "weights.tolist() # portfolio weights",
   "id": "6c0a7f83a683f5f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21484653651714325, 0.5542225241661072, 0.23093098402023315]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:41.366615Z",
     "start_time": "2025-01-25T10:57:41.363474Z"
    }
   },
   "cell_type": "code",
   "source": "portfolio_return(weights, expected_returns).item() # expected return",
   "id": "8bdf06728e41de49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999465823173523"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T10:57:45.352364Z",
     "start_time": "2025-01-25T10:57:45.348918Z"
    }
   },
   "cell_type": "code",
   "source": "portfolio_risk(weights, cov_matrix).item() # risk",
   "id": "431b3de01bec419c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03904213756322861"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
